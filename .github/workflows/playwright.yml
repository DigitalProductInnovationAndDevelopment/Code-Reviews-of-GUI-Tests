name: GUI Test Review

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  check-code-quality:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with: { node-version: 18 }
      
      - name: Install dependencies
        run: npm install
      
      # Set up reviewdog
      - uses: reviewdog/action-setup@v1
        with:
          reviewdog_version: latest
      
      - name: Create detailed Prettier report
        id: prettier-report
        run: |
          # Find files with Prettier issues
          FILES_WITH_ISSUES=$(npx prettier --check "tests/**/*.{js,ts,tsx,json}" 2>&1 | grep -oE "[^ ]+\.(js|ts|tsx|json)" || echo "")
          
          if [ -n "$FILES_WITH_ISSUES" ]; then
            # Count files
            FILE_COUNT=$(echo "$FILES_WITH_ISSUES" | wc -l)
            echo "prettier_files=$FILE_COUNT" >> $GITHUB_OUTPUT
            
            # Create temp dir for reports
            mkdir -p temp_prettier
            
            # Process each file
            TOTAL_ISSUES=0
            for FILE in $FILES_WITH_ISSUES; do
              # Get prettier formatted version
              FORMATTED=$(npx prettier "$FILE")
              ORIGINAL=$(cat "$FILE")
              
              # Save formatted version
              echo "$FORMATTED" > "temp_prettier/$FILE.formatted"
              
              # Create line-by-line diff for the file
              DIFF_OUTPUT=$(diff -u "$FILE" "temp_prettier/$FILE.formatted" || true)
              
              # Count only actual changed lines (excluding context and metadata lines)
              CHANGED_LINES=$(echo "$DIFF_OUTPUT" | grep -E "^[+-][^+-]" | wc -l)
              TOTAL_ISSUES=$((TOTAL_ISSUES + CHANGED_LINES))
              
              echo "File $FILE has approximately $CHANGED_LINES formatting issues"
              
              # Add file headers for proper reviewdog diff format
              FIXED_DIFF=$(echo "$DIFF_OUTPUT" | sed "1s|---|--- a/$FILE|" | sed "2s|+++|+++ b/$FILE|")
              echo "$FIXED_DIFF" > "temp_prettier/$FILE.diff"
              
              # Run reviewdog on this file's diff to create inline comments
              cat "temp_prettier/$FILE.diff" | REVIEWDOG_GITHUB_API_TOKEN=${{ secrets.GITHUB_TOKEN }} reviewdog -f=diff -name=prettier -reporter=github-pr-review -filter-mode=nofilter -level=warning -fail-on-error=false
            done
            
            echo "prettier_issues=$TOTAL_ISSUES" >> $GITHUB_OUTPUT
            echo "Found $FILE_COUNT files with approximately $TOTAL_ISSUES Prettier issues"
            
            # Save file list
            echo "$FILES_WITH_ISSUES" > temp_prettier/files.txt
            echo "prettier_file_list<<EOF" >> $GITHUB_OUTPUT
            cat temp_prettier/files.txt >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            
            # Create the summary JSON for dashboard
            mkdir -p artifacts
            echo "{\"files\": $FILE_COUNT, \"issues\": $TOTAL_ISSUES, \"fileList\": [\"$(echo $FILES_WITH_ISSUES | sed 's/ /", "/g')\"]}" > artifacts/prettier-report.json
          else
            echo "prettier_files=0" >> $GITHUB_OUTPUT
            echo "prettier_issues=0" >> $GITHUB_OUTPUT
            echo "No Prettier issues found"
            
            # Create empty report
            mkdir -p artifacts
            echo "{\"files\": 0, \"issues\": 0, \"fileList\": []}" > artifacts/prettier-report.json
          fi
      
      - name: Create detailed ESLint report
        id: eslint-report
        run: |
          # Run ESLint and get JSON output
          mkdir -p artifacts
          ESLINT_OUTPUT=$(npx eslint tests --ext .js,.ts,.tsx -f json || true)
          echo "$ESLINT_OUTPUT" > artifacts/eslint-results.json
          
          # Check if output is valid JSON
          if echo "$ESLINT_OUTPUT" | jq empty 2>/dev/null; then
            # Count issues
            TOTAL_ISSUES=$(echo "$ESLINT_OUTPUT" | jq '[.[].messages | length] | add')
            ERROR_COUNT=$(echo "$ESLINT_OUTPUT" | jq '[.[].messages | .[] | select(.severity == 2)] | length')
            WARNING_COUNT=$(echo "$ESLINT_OUTPUT" | jq '[.[].messages | .[] | select(.severity == 1)] | length')
            
            echo "eslint_errors=$ERROR_COUNT" >> $GITHUB_OUTPUT
            echo "eslint_warnings=$WARNING_COUNT" >> $GITHUB_OUTPUT
            echo "eslint_total=$TOTAL_ISSUES" >> $GITHUB_OUTPUT
            
            # Count files with issues
            FILE_COUNT=$(echo "$ESLINT_OUTPUT" | jq '[.[].filePath] | unique | length')
            echo "eslint_files=$FILE_COUNT" >> $GITHUB_OUTPUT
            
            echo "Found $TOTAL_ISSUES ESLint issues ($ERROR_COUNT errors, $WARNING_COUNT warnings) in $FILE_COUNT files"
            
            # Create summary JSON
            echo "{\"total\": $TOTAL_ISSUES, \"errors\": $ERROR_COUNT, \"warnings\": $WARNING_COUNT, \"files\": $FILE_COUNT}" > artifacts/eslint-report.json
            
            # Run reviewdog on the ESLint output to create inline comments
            cat artifacts/eslint-results.json | REVIEWDOG_GITHUB_API_TOKEN=${{ secrets.GITHUB_TOKEN }} reviewdog -f=eslint -name=eslint -reporter=github-pr-review -filter-mode=nofilter -level=warning -fail-on-error=false
          else
            echo "eslint_errors=0" >> $GITHUB_OUTPUT
            echo "eslint_warnings=0" >> $GITHUB_OUTPUT
            echo "eslint_total=0" >> $GITHUB_OUTPUT
            echo "eslint_files=0" >> $GITHUB_OUTPUT
            echo "No ESLint issues found or invalid output"
            
            # Create empty report
            echo "{\"total\": 0, \"errors\": 0, \"warnings\": 0, \"files\": 0}" > artifacts/eslint-report.json
          fi
      
      # Create a custom lint-summary.json that includes the correct counts
      - name: Create correct lint-summary.json
        run: |
          mkdir -p artifacts
          cat > artifacts/lint-summary.json << EOF
          {
            "prettier": {
              "filesWithIssues": ${{ steps.prettier-report.outputs.prettier_files || 0 }},
              "totalChanges": ${{ steps.prettier-report.outputs.prettier_issues || 0 }},
              "files": $([ -n "${{ steps.prettier-report.outputs.prettier_file_list }}" ] && echo "[\"$(echo ${{ steps.prettier-report.outputs.prettier_file_list }} | sed 's/ /", "/g')\"]" || echo "[]")
            },
            "eslint": {
              "files": ${{ steps.eslint-report.outputs.eslint_files || 0 }},
              "errors": ${{ steps.eslint-report.outputs.eslint_errors || 0 }},
              "warnings": ${{ steps.eslint-report.outputs.eslint_warnings || 0 }},
              "fixableErrors": 0,
              "fixableWarnings": 0
            }
          }
          EOF
          
          echo "Created correct lint-summary.json with proper counts"
          cat artifacts/lint-summary.json
      
      # Create PR comment
      - name: Create PR comment
        uses: peter-evans/create-or-update-comment@v3
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ## ðŸ” Code Quality Check Results
            
            ### Prettier
            
            ${{ steps.prettier-report.outputs.prettier_files == '0' && 'âœ… No formatting issues found' || format('âŒ Found **{0} files** with approximately **{1} formatting issues**.', steps.prettier-report.outputs.prettier_files, steps.prettier-report.outputs.prettier_issues) }}
            
            ${{ steps.prettier-report.outputs.prettier_files != '0' && 'Check the "Files changed" tab to see inline suggestions for formatting issues.' || '' }}
            
            <details>
            <summary>Click to see all files with Prettier issues</summary>
            
            ```
            ${{ steps.prettier-report.outputs.prettier_file_list }}
            ```
            
            Each file has multiple formatting issues. The most common issues are:
            - Single quotes vs double quotes
            - Trailing commas
            - Indentation
            - Line breaks
            - Spacing around operators
            
            </details>
            
            ### ESLint
            
            ${{ steps.eslint-report.outputs.eslint_total == '0' && 'âœ… No linting issues found' || format('âŒ Found **{0} issues** ({1} errors, {2} warnings).', steps.eslint-report.outputs.eslint_total, steps.eslint-report.outputs.eslint_errors, steps.eslint-report.outputs.eslint_warnings) }}
            
            ${{ steps.eslint-report.outputs.eslint_total != '0' && 'Check the "Files changed" tab to see inline suggestions for ESLint issues.' || '' }}
            
            ### How to fix all issues locally
            
            ```bash
            # Fix Prettier issues:
            npx prettier --write "tests/**/*.{js,ts,tsx,json}"
            
            # Fix ESLint issues:
            npx eslint --fix tests --ext .js,.ts,.tsx
            ```
            
            Please fix these issues before merging!
          edit-mode: replace
      
      # Upload artifacts
      - uses: actions/upload-artifact@v4
        with:
          name: lint-artifacts
          path: |
            artifacts/*
            temp_prettier/*
  
  run-tests:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with: { node-version: 18 }
      
      - name: Install dependencies
        run: npm install
      
      # Run your tests and other steps
      - name: Playwright tests
        run: node scripts/playwright-test.js
        continue-on-error: true
      
      - name: Generate flow-chart
        run: node scripts/generate-flowchart.js
        continue-on-error: true
      
      - name: Build checklist
        run: node scripts/checklist.js
        continue-on-error: true
      
      - name: Build static HTML report
        run: node scripts/generate-webpage.js
        continue-on-error: true
      
      - name: Create test-summary badge
        run: |
          mkdir -p artifacts
          if [ -f "artifacts/playwright-summary.json" ]; then
            jq -r '"Total: \(.total) | Passed: \(.passed) | Failed: \(.failed) | Skipped: \(.skipped)"' \
              artifacts/playwright-summary.json > artifacts/test-summary.txt
          else
            echo "No playwright-summary.json file found. Creating empty summary."
            echo "Total: 0 | Passed: 0 | Failed: 0 | Skipped: 0" > artifacts/test-summary.txt
          fi
        continue-on-error: true
      
      # Upload test artifacts
      - uses: actions/upload-artifact@v4
        with:
          name: test-artifacts
          path: artifacts/*
  
  deploy-report:
    needs: [check-code-quality, run-tests]
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deploy.outputs.page_url }}
    
    steps:
      - uses: actions/download-artifact@v4
        with: { name: lint-artifacts, path: lint-artifacts }
        continue-on-error: true
      
      - uses: actions/download-artifact@v4
        with: { name: test-artifacts, path: test-artifacts }
        continue-on-error: true
      
      - name: Combine artifacts
        run: |
          mkdir -p combined-artifacts
          cp -r lint-artifacts/* combined-artifacts/ || true
          cp -r test-artifacts/* combined-artifacts/ || true
      
      - uses: actions/upload-pages-artifact@v3
        with: { path: combined-artifacts/web-report }
        continue-on-error: true
      
      - id: deploy
        uses: actions/deploy-pages@v4
        continue-on-error: true
  
  comment_link:
    if: github.event_name == 'pull_request'
    needs: deploy-report
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
    
    steps:
      - uses: actions/checkout@v4
        continue-on-error: true
      
      - uses: actions/setup-node@v4
        with: { node-version: 18 }
        continue-on-error: true
      
      - name: Install JS dependencies (Octokit, marked, etc.)
        run: npm install
        continue-on-error: true
      
      - uses: actions/download-artifact@v4
        with:
          name: lint-artifacts
          path: lint-artifacts
        continue-on-error: true
      
      - uses: actions/download-artifact@v4
        with:
          name: test-artifacts
          path: test-artifacts
        continue-on-error: true
      
      - name: Combine artifacts
        run: |
          mkdir -p artifacts
          cp -r lint-artifacts/* artifacts/ || true
          cp -r test-artifacts/* artifacts/ || true
      
      - name: Post / update GUI-test summary comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ARTIFACTS_DIR: artifacts
          WEB_REPORT_URL: https://digitalproductinnovationanddevelopment.github.io/Code-Reviews-of-GUI-Tests/index.html
        run: node scripts/summary-comment.js
        continue-on-error: true
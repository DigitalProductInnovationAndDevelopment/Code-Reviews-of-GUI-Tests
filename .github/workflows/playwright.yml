name: Playwright Tests + Prettier (reviewdog) + test-flow chart

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Still needed for Prettier patch if it makes changes
      pull-requests: write # Needed for sticky PR comment

    steps:
    #---------------------------------------------------
    # 0 – Checkout
    #---------------------------------------------------
    - name: Checkout PR branch code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0 # Needed to fetch origin/main later
        ref: ${{ github.event.pull_request.head.ref }} # Checkout PR branch first

    #---------------------------------------------------
    # 1 – reviewdog CLI
    #---------------------------------------------------
    - name: Setup reviewdog
      uses: reviewdog/action-setup@v1
      with: { reviewdog_version: latest }

    #---------------------------------------------------
    # 2 – Prettier → inline review comments
    #---------------------------------------------------
    - name: Prettier style check (reviewdog)
      shell: bash
      env:
        REVIEWDOG_GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        npx prettier --write '**/*.{js,ts,tsx,jsx,json,yml,yaml,md}' || true # Allow Prettier to run without failing the step
        git diff -U0 --no-color > prettier.patch || true
        if [ -s prettier.patch ]; then
          cat prettier.patch | reviewdog -f=diff \
                                         -name="prettier" \
                                         -reporter=github-pr-review \
                                         -filter-mode=diff_context \
                                         -level=warning
        else
          echo "No Prettier issues found."
        fi

    #---------------------------------------------------
    # 3 – Node & deps
    #---------------------------------------------------
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with: { node-version: 18 }

    - name: Install dependencies
      run: npm install

    # --- IMPORTANT: Install Playwright browsers early ---
    - name: Install Playwright and browsers
      run: npx playwright install --with-deps

    ## CORE LOGIC FOR BEFORE/AFTER COMPARISON ##

    # Step 1: Save current PR's test files (before checking out main's version)
    - name: Save PR test files
      run: |
        mkdir -p tests_pr_backup/
        cp -r tests/ tests_pr_backup/ # Copy the 'tests' directory and its contents
        echo "Contents of tests_pr_backup/:"
        ls -la tests_pr_backup/ # Debugging: verify backup content

    # Step 2: Checkout base branch version of test files (from main)
    - name: Checkout base version of test files from main
      run: |
        git fetch origin main # Ensure origin/main is up-to-date
        # This will put 'tests/' from origin/main into your working directory, overwriting current 'tests/'
        git checkout --force origin/main -- tests/
        echo "Contents of tests/ after checking out main's version:"
        ls -la tests/ # Debugging

    # Step 3: Run Playwright on base version (for "before" view)
    - name: Run Playwright "before" tests on Main's version
      env:
        # This ENV variable is picked up by playwright.config.js for the 'output' path
        PLAYWRIGHT_SCREENSHOT_DIR: playwright-artifacts-before
      run: |
        mkdir -p $PLAYWRIGHT_SCREENSHOT_DIR # Ensure the directory exists
        echo "Running Playwright 'before' tests, outputting to: $PLAYWRIGHT_SCREENSHOT_DIR"
        # Using --reporter=json for Playwright's default json report for summary extraction
        npx playwright test --output=$PLAYWRIGHT_SCREENSHOT_DIR --reporter=json --debug || true
        # The '|| true' allows the workflow to continue even if Playwright fails, so we can inspect artifacts
        
        # Debugging: List contents after run
        echo "Contents of $PLAYWRIGHT_SCREENSHOT_DIR after 'before' tests:"
        ls -laR $PLAYWRIGHT_SCREENSHOT_DIR || true # List even if directory is empty or missing

    # Step 4: Restore PR version of tests
    - name: Restore PR test files
      run: |
        rm -rf tests/ # Remove tests/ from main's version
        mv tests_pr_backup/ tests/ # Move the backup back to become the PR's tests/
        echo "Contents of tests/ after restoring PR's version:"
        ls -la tests/ # Debugging

    #---------------------------------------------------
    # 5 – Run Playwright tests (This now runs on the PR branch's tests)
    #---------------------------------------------------
    - name: Run Playwright tests (PR version)
      env:
        # This ENV variable is picked up by playwright.config.js for the 'output' path
        PLAYWRIGHT_SCREENSHOT_DIR: playwright-artifacts-pr
      run: |
        mkdir -p $PLAYWRIGHT_SCREENSHOT_DIR # Ensure the directory exists
        echo "Running Playwright 'PR' tests, outputting to: $PLAYWRIGHT_SCREENSHOT_DIR"
        # Use html reporter here so we can upload the full interactive report
        npx playwright test --output=$PLAYWRIGHT_SCREENSHOT_DIR --reporter=html,json --debug || true
        # The '|| true' allows the workflow to continue even if Playwright fails

        # Debugging: List contents after run
        echo "Contents of $PLAYWRIGHT_SCREENSHOT_DIR after 'PR' tests:"
        ls -laR $PLAYWRIGHT_SCREENSHOT_DIR || true

    # --- Debugging: Verify Playwright Report Existence AFTER tests ---
    - name: Verify Playwright Report Existence (PR version)
      run: |
        # Check in the explicitly set output directory
        REPORT_FILE="playwright-artifacts-pr/results.json" # Playwright's JSON reporter outputs to results.json
        echo "Checking for report file at: $REPORT_FILE"
        if [ -f "$REPORT_FILE" ]; then
          echo "$REPORT_FILE exists."
        else
          echo "ERROR: $REPORT_FILE DOES NOT EXIST. Listing parent directory contents:"
          ls -la playwright-artifacts-pr/ || true # List even if directory is empty or missing
          exit 1
        fi
    # --- End Debugging ---

    # --- START OF ARTIFACT UPLOADS ---

    - name: Upload 'Before' Playwright Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: playwright-artifacts-before
        path: playwright-artifacts-before/
        retention-days: 7 # Optional: How long to keep the artifact

    - name: Upload 'After' Playwright Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: playwright-artifacts-pr
        path: playwright-artifacts-pr/
        retention-days: 7 # Optional: How long to keep the artifact

    # --- END OF ARTIFACT UPLOADS ---

    #---------------------------------------------------
    # 6 – Upload HTML report (Still useful, points to the PR run's html folder)
    #---------------------------------------------------
    - name: Upload HTML report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: playwright-html-report
        # Playwright's HTML report is usually in a subfolder named 'html/' within the output directory
        path: playwright-artifacts-pr/html/

    #---------------------------------------------------
    # 7 – Extract test summary
    #---------------------------------------------------
    - name: Extract Playwright test summary
      id: summary
      run: |
        # Playwright's JSON report contains the summary statistics.
        # It's now in the 'playwright-artifacts-pr/' directory.
        REPORT_FILE="playwright-artifacts-pr/results.json"
        if [ ! -f "$REPORT_FILE" ]; then
          echo "Error: Playwright report file not found at $REPORT_FILE"
          # Exit 0 here so the sticky comment can still be posted with an error message
          echo "total=N/A" >> $GITHUB_OUTPUT
          echo "passed=N/A" >> $GITHUB_OUTPUT
          echo "failed=N/A" >> $GITHUB_OUTPUT
          echo "skipped=N/A" >> $GITHUB_OUTPUT
          echo "duration=N/A" >> $GITHUB_OUTPUT
          echo "passrate=N/A" >> $GITHUB_OUTPUT
          exit 0 # Allow workflow to continue for debugging info in PR comment
        fi
        
        TOTAL=$(jq '.stats.total' "$REPORT_FILE")
        PASSED=$(jq '.stats.expected' "$REPORT_FILE")
        FAILED=$(jq '.stats.failures' "$REPORT_FILE")
        SKIPPED=$(jq '.stats.skipped' "$REPORT_FILE")
        DURATION=$(jq '.stats.duration' "$REPORT_FILE") # Playwright duration is already in ms
        PASS_RATE=$(awk "BEGIN{printf \"%.2f\", ($TOTAL==0)?0:($PASSED/$TOTAL)*100}")
        
        echo "total=$TOTAL" >> $GITHUB_OUTPUT
        echo "passed=$PASSED" >> $GITHUB_OUTPUT
        echo "failed=$FAILED" >> $GITHUB_OUTPUT
        echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
        echo "duration=$DURATION" >> $GITHUB_OUTPUT
        echo "passrate=$PASS_RATE" >> $GITHUB_OUTPUT

    #---------------------------------------------------
    # 8 – ESLint (tests only)
    #---------------------------------------------------
    - name: Run ESLint on GUI tests
      shell: bash
      run: |
        # Run ESLint and redirect output to a file. The `|| true` prevents the step from failing if lint issues are found.
        npx eslint "tests/**/*.{js,ts,tsx}" -f stylish > eslint-tests.txt || true

    - name: Upload ESLint report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: eslint-test-report
        path: eslint-tests.txt

    - name: Read ESLint report (preview)
      id: lint_summary
      run: |
        # Only read if the file exists, to prevent errors
        if [ -f "eslint-tests.txt" ]; then
          echo 'summary<<EOF' >> $GITHUB_OUTPUT
          head -n 20 eslint-tests.txt >> $GITHUB_OUTPUT
          echo 'EOF' >> $GITHUB_OUTPUT
        else
          echo 'summary<<EOF' >> $GITHUB_OUTPUT
          echo 'ESLint report not generated or found.' >> $GITHUB_OUTPUT
          echo 'EOF' >> $GITHUB_OUTPUT
        fi

    #---------------------------------------------------
    # 9 – Generate Suite→Spec Mermaid chart (flowchart.png)
    #---------------------------------------------------
    - name: Generate test-flow chart
      shell: bash
      run: |
        set -e
        # The report file for the flowchart should be from the PR's run
        REPORT_FILE="playwright-artifacts-pr/results.json"
        if [ ! -f "$REPORT_FILE" ]; then
          echo "Error: Playwright report file not found at $REPORT_FILE for flowchart generation. Skipping chart."
          exit 0 # Exit successfully if report not found, but log message
        fi
        
        echo "graph TD" > flowchart.mmd

        jq -r '
          .suites[] as $file |
          ($file.title // "NO_FILE_TITLE") as $fileTitle |
          $file.suites[]? as $suite |
            ($suite.title // "NO_SUITE_TITLE") as $suiteTitle |
            $suite.specs[]? as $spec |
              ($spec.title // "NO_SPEC_TITLE") as $specTitle |
              [$fileTitle, $suiteTitle, $specTitle] | @tsv
        ' "$REPORT_FILE" |
        while IFS=$'\t' read -r fileTitle suiteTitle specTitle; do
          # Build unique, safe IDs by combining parent and child
          fileId=$(echo "$fileTitle" | tr -c 'A-Za-z0-9' '_' | sed 's/^_*\|_*$//g')
          suiteId=$(echo "${fileTitle}_${suiteTitle}" | tr -c 'A-Za-z0-9' '_' | sed 's/^_*\|_*$//g')
          specId=$(echo "${fileTitle}_${suiteTitle}_${specTitle}" | tr -c 'A-Za-z0-9' '_' | sed 's/^_*\|_*$//g')

          # File node
          if ! grep -q "^  ${fileId}\[" flowchart.mmd; then
            echo "  ${fileId}[\"${fileTitle}\"]" >> flowchart.mmd
          fi
          # Suite node
          if ! grep -q "^  ${suiteId}\[" flowchart.mmd; then
            echo "  ${suiteId}[\"${suiteTitle}\"]" >> flowchart.mmd
            echo "  ${fileId} --> ${suiteId}" >> flowchart.mmd
          fi
          # Spec node/edge
          echo "  ${suiteId} --> ${specId}[\"${specTitle}\"]" >> flowchart.mmd
        done

        printf '{ "args": ["--no-sandbox","--disable-setuid-sandbox"] }\n' > puppeteer.json

        npx -y @mermaid-js/mermaid-cli@10.6.1 \
          -p puppeteer.json \
          -i flowchart.mmd \
          -o flowchart.png

        ls -lh flowchart.png

    - name: Show flowchart.mmd for debugging
      run: cat flowchart.mmd

    - name: Upload test-flow chart
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-flow-chart
        path: flowchart.png

    #---------------------------------------------------
    # 10 – Sticky PR comment (Simplified)
    #---------------------------------------------------
    - name: Comment on PR with results
      uses: marocchino/sticky-pull-request-comment@v2
      with:
        message: |
          ## Playwright Test Metrics
          *Total:* **${{ steps.summary.outputs.total }}**
          *Passed:* **${{ steps.summary.outputs.passed }}**
          *Failed:* **${{ steps.summary.outputs.failed }}**
          *Skipped:* **${{ steps.summary.outputs.skipped }}**

          Duration: **${{ steps.summary.outputs.duration }} ms**
          Pass Rate: **${{ steps.summary.outputs.passrate }} %**

          ## ESLint (GUI tests)
          ```
          ${{ steps.lint_summary.outputs.summary }}
          ```

          ## Test-Flow Chart
          Artifact: **test-flow-chart → flowchart.png**

          ---

          **View Before/After Screenshots and Full Reports:**
          You can download the following artifacts from this workflow run's summary page:
          * **`playwright-artifacts-before`**: Contains screenshots and data from tests run against the `main` branch.
          * **`playwright-artifacts-pr`**: Contains screenshots and data from tests run against this PR's branch.
          * **`playwright-html-report`**: The full interactive Playwright HTML report for this PR's branch.
          * **`eslint-test-report`**: Detailed ESLint results.

          _Full run details:_ [link](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

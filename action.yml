name: 'GUI-Based Testing Code Review'
description: 'Enhance code review process for automated GUI tests by integrating visual context directly into GitHub pull requests'
author: 'Digital Product Innovation and Development - TUM'

branding:
  icon: 'eye'
  color: 'purple'

inputs:
  github-token:
    description: 'GitHub token for API access and reviewdog integration'
    required: true
    default: ${{ github.token }}
  
  test-files:
    description: 'Glob pattern for GUI test files to analyze'
    required: false
    default: 'tests/**/*.spec.{js,ts,tsx}'
  
  node-version:
    description: 'Node.js version to use'
    required: false
    default: '18'
  
  enable-pr-comments:
    description: 'Whether to post comprehensive PR comments with visual feedback'
    required: false
    default: 'true'
  
  enable-github-pages:
    description: 'Whether to deploy visual dashboard to GitHub Pages'
    required: false
    default: 'true'
  
  reviewdog-reporter:
    description: 'Reviewdog reporter for inline code quality feedback'
    required: false
    default: 'github-pr-review'
  
  artifacts-retention-days:
    description: 'Number of days to retain test artifacts and screenshots'
    required: false
    default: '30'
  
  web-report-url:
    description: 'Base URL for the visual dashboard (auto-generated if not provided)'
    required: false
    default: ''
  
  fail-on-test-failure:
    description: 'Whether to fail the action if GUI tests fail'
    required: false
    default: 'false'
  
  playwright-config:
    description: 'Path to Playwright configuration file'
    required: false
    default: 'playwright.config.js'
  
  enable-visual-comparison:
    description: 'Enable visual comparison between PR and main branch test results'
    required: false
    default: 'true'
  
  main-branch:
    description: 'Main branch name for visual comparison testing'
    required: false
    default: 'main'
  
  key-test-file:
    description: 'Key test file to verify successful main branch checkout'
    required: false
    default: 'tests/demo-todo-app.spec.ts'

outputs:
  test-results:
    description: 'Comprehensive JSON summary of GUI test results'
    value: ${{ steps.test-summary.outputs.results }}
  
  visual-artifacts-path:
    description: 'Path to generated visual artifacts and screenshots'
    value: ${{ steps.setup.outputs.artifacts-path }}
  
  dashboard-url:
    description: 'URL to the deployed visual testing dashboard'
    value: ${{ steps.deploy-report.outputs.page_url }}
  
  test-pass-rate:
    description: 'GUI test pass rate percentage'
    value: ${{ steps.test-summary.outputs.pass-rate }}
  
  total-gui-tests:
    description: 'Total number of GUI tests executed'
    value: ${{ steps.test-summary.outputs.total-tests }}
  
  code-quality-score:
    description: 'Overall code quality score based on linting results'
    value: ${{ steps.lint-summary.outputs.quality-score }}
  
  pr-test-results:
    description: 'JSON summary of PR branch GUI test results'
    value: ${{ steps.test-summary.outputs.pr-results }}
  
  main-test-results:
    description: 'JSON summary of main branch GUI test results'
    value: ${{ steps.test-summary.outputs.main-results }}
  
  visual-comparison:
    description: 'Visual comparison analysis between PR and main branch'
    value: ${{ steps.test-summary.outputs.visual-comparison }}
  
  gui-regression-detected:
    description: 'Whether GUI test regression was detected in PR'
    value: ${{ steps.test-summary.outputs.regression-detected }}
  
  review-checklist-status:
    description: 'Status of the code review checklist completion'
    value: ${{ steps.checklist.outputs.status }}

runs:
  using: 'composite'
  steps:
    - name: Setup GUI testing environment
      id: setup
      shell: bash
      run: |
        echo "ğŸš€ Setting up GUI-Based Testing Code Review environment..."
        mkdir -p artifacts
        echo "artifacts-path=artifacts" >> $GITHUB_OUTPUT
        
        # Copy action scripts to workspace if using published action
        if [ -d "${{ github.action_path }}/scripts" ]; then
          echo "ğŸ“‚ Copying action scripts to workspace..."
          mkdir -p .gui-test-review-action/scripts
          cp -r "${{ github.action_path }}/scripts"/* .gui-test-review-action/scripts/
          
          # Create a minimal package.json for action dependencies
          cat > .gui-test-review-action/package.json << 'EOF'
        {
          "name": "gui-test-review-action-deps",
          "version": "1.0.0",
          "private": true,
          "dependencies": {
            "@octokit/core": "^5.0.0",
            "marked": "15.0.12"
          }
        }
        EOF
        fi
        
        echo "âœ… Environment ready for visual GUI test analysis"
    
    - name: Setup Node.js for GUI test tools
      uses: actions/setup-node@v4
      with:
        node-version: ${{ inputs.node-version }}
    
    - name: Install GUI testing dependencies
      shell: bash
      run: |
        echo "ğŸ“¦ Installing dependencies for GUI test analysis..."
        
        # Install project dependencies if package.json exists
        if [ -f "package.json" ]; then
          npm install
          echo ""
          echo "--- Installed Top-Level Dependencies ---"
          
          # List the installed packages. --depth=0 keeps the list clean.
          npm list --depth=0
          echo "----------------------------------------"
          echo "âœ… Dependencies installed successfully"

        else
          echo "âš ï¸ No package.json found, skipping npm install"
        fi
        
        # Install action dependencies if we copied scripts
        if [ -d ".gui-test-review-action" ]; then
          echo "ğŸ“¦ Installing action dependencies..."
          cd .gui-test-review-action
          npm install --production
          cd ..
        fi
        
        echo "âœ… Dependencies installed successfully"
    
    - name: Install Playwright browsers for GUI testing
      shell: bash
      run: |
        echo "ğŸ­ Installing Playwright browsers for GUI testing..."
        npx playwright install --with-deps
        echo "âœ… Playwright browsers ready for GUI test execution"
    
    - name: Setup reviewdog for code quality feedback
      uses: reviewdog/action-setup@v1
      if: github.event_name == 'pull_request'
      with:
        reviewdog_version: latest
    
    - name: Run code quality analysis with visual feedback
      id: lint
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        REVIEWDOG_GITHUB_API_TOKEN: ${{ inputs.github-token }}
        REVIEWDOG_REPORTER: ${{ inputs.reviewdog-reporter }}
      run: |
        echo "ğŸ” Running code quality analysis for GUI tests..."
        
        # Determine script location
        SCRIPT_PATH=""
        if [ -f ".gui-test-review-action/scripts/lint.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/lint.js"
        elif [ -f "${{ github.action_path }}/scripts/lint.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/lint.js"
        elif [ -f "scripts/lint.js" ]; then
          SCRIPT_PATH="scripts/lint.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          node "$SCRIPT_PATH"
        else
          echo "âš ï¸ Lint script not found, skipping code quality analysis"
        fi
        echo "âœ… Code quality analysis completed"
      continue-on-error: true
    
    - name: Execute GUI tests on PR branch
      id: gui-tests-pr
      shell: bash
      env:
        PLAYWRIGHT_CONFIG: ${{ inputs.playwright-config }}
        TEST_FILES: ${{ inputs.test-files }}
      run: |
        echo "ğŸ§ª Executing GUI tests on PR branch..."
        
        # Determine script location
        SCRIPT_PATH=""
        if [ -f ".gui-test-review-action/scripts/playwright-test.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/playwright-test.js"
        elif [ -f "${{ github.action_path }}/scripts/playwright-test.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/playwright-test.js"
        elif [ -f "scripts/playwright-test.js" ]; then
          SCRIPT_PATH="scripts/playwright-test.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          node "$SCRIPT_PATH"
        else
          echo "ğŸ­ Running Playwright tests directly..."
          npx playwright test ${{ inputs.test-files }}
        fi
        echo "âœ… PR branch GUI tests completed"
      continue-on-error: true
    
    - name: Archive PR GUI test results and screenshots
      shell: bash
      run: |
        echo "ğŸ“ Archiving PR branch GUI test artifacts..."
        mkdir -p artifacts
        if [[ -f artifacts/playwright-summary.json ]]; then
          cp artifacts/playwright-summary.json artifacts/playwright-summary-pr.json
          echo "âœ… PR test summary archived"
        else
          echo "{}" > artifacts/playwright-summary-pr.json
          echo "âš ï¸ No PR summary found, created empty file"
        fi
        
        # Archive HTML report with screenshots
        mkdir -p artifacts/pr-report
        if [ -d "playwright-report" ] && [ "$(ls -A playwright-report)" ]; then
          mv playwright-report/* artifacts/pr-report/ || echo "No PR report contents to move"
          echo "âœ… PR GUI test report with screenshots archived"
        else
          echo "âš ï¸ No PR report found to archive"
        fi
      continue-on-error: true
    
    - name: Execute GUI tests on main branch for visual comparison
      id: gui-tests-main
      if: inputs.enable-visual-comparison == 'true' && github.event_name == 'pull_request'
      shell: bash
      env:
        MAIN_BRANCH: ${{ inputs.main-branch }}
        KEY_TEST_FILE: ${{ inputs.key-test-file }}
      run: |
        echo "ğŸ”„ Checking out main branch GUI tests for comparison..."
        
        # Checkout main branch test files for comparison
        git checkout origin/$MAIN_BRANCH -- tests/ playwright.config.js || true
        
        # Verify successful checkout
        if [ ! -f "$KEY_TEST_FILE" ]; then
          echo "âš ï¸ Key test file '$KEY_TEST_FILE' not found. Skipping main branch comparison."
          mkdir -p playwright-report
          echo "{}" > artifacts/playwright-summary-main.json
        else
          echo "âœ… Main branch test files checked out successfully"
          echo "ğŸ§ª Running GUI tests on main branch version..."
          
          # Determine script location
          SCRIPT_PATH=""
          if [ -f ".gui-test-review-action/scripts/playwright-test.js" ]; then
            SCRIPT_PATH=".gui-test-review-action/scripts/playwright-test.js"
          elif [ -f "${{ github.action_path }}/scripts/playwright-test.js" ]; then
            SCRIPT_PATH="${{ github.action_path }}/scripts/playwright-test.js"
          elif [ -f "scripts/playwright-test.js" ]; then
            SCRIPT_PATH="scripts/playwright-test.js"
          fi
          
          if [ -n "$SCRIPT_PATH" ]; then
            node "$SCRIPT_PATH"
          else
            npx playwright test ${{ inputs.test-files }}
          fi
          echo "âœ… Main branch GUI tests completed"
        fi
      continue-on-error: true
    
    - name: Archive main branch GUI test results for comparison
      if: inputs.enable-visual-comparison == 'true' && github.event_name == 'pull_request'
      shell: bash
      run: |
        echo "ğŸ“ Archiving main branch GUI test artifacts..."
        if [[ -f artifacts/playwright-summary.json ]]; then
          cp artifacts/playwright-summary.json artifacts/playwright-summary-main.json
          echo "âœ… Main branch test summary archived"
        else
          echo "{}" > artifacts/playwright-summary-main.json
          echo "âš ï¸ No main branch summary found, created empty file"
        fi
        
        # Archive main branch HTML report
        mkdir -p artifacts/main-report
        if [ -d "playwright-report" ] && [ "$(ls -A playwright-report)" ]; then
          mv playwright-report/* artifacts/main-report/ || echo "No main branch report contents to move"
          echo "âœ… Main branch GUI test report archived"
        else
          echo "âš ï¸ No main branch report found to archive"
        fi
      continue-on-error: true
    
    - name: Restore PR test files
      if: inputs.enable-visual-comparison == 'true' && github.event_name == 'pull_request'
      shell: bash
      run: |
        echo "ğŸ”„ Restoring PR branch test files..."
        git checkout HEAD -- tests/ playwright.config.js
        echo "âœ… PR test files restored"
      continue-on-error: true
    
    - name: Generate visual flow chart of GUI tests
      id: flowchart
      shell: bash
      run: |
        echo "ğŸ“Š Generating visual flowchart of GUI test execution..."
        
        # Determine script location
        SCRIPT_PATH=""
        if [ -f ".gui-test-review-action/scripts/generate-flowchart.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/generate-flowchart.js"
        elif [ -f "${{ github.action_path }}/scripts/generate-flowchart.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/generate-flowchart.js"
        elif [ -f "scripts/generate-flowchart.js" ]; then
          SCRIPT_PATH="scripts/generate-flowchart.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          node "$SCRIPT_PATH"
        else
          echo "âš ï¸ Flowchart script not found, skipping visualization"
        fi
        echo "âœ… Visual flowchart generation completed"
      continue-on-error: true
    
    - name: Build review checklist for code reviewers
      id: checklist
      shell: bash
      run: |
        echo "ğŸ“‹ Building comprehensive review checklist..."
        
        # Determine script location
        SCRIPT_PATH=""
        if [ -f ".gui-test-review-action/scripts/checklist.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/checklist.js"
        elif [ -f "${{ github.action_path }}/scripts/checklist.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/checklist.js"
        elif [ -f "scripts/checklist.js" ]; then
          SCRIPT_PATH="scripts/checklist.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          node "$SCRIPT_PATH"
        else
          echo "âš ï¸ Checklist script not found, skipping checklist generation"
        fi
        
        # Set checklist status output
        if [ -f "artifacts/checklist.json" ]; then
          echo "status=completed" >> $GITHUB_OUTPUT
        else
          echo "status=incomplete" >> $GITHUB_OUTPUT
        fi
        echo "âœ… Review checklist generation completed"
      continue-on-error: true
    
    - name: Build visual dashboard for code reviewers
      id: dashboard
      shell: bash
      run: |
        echo "ğŸ¨ Building interactive visual dashboard..."
        
        # Determine script location and set NODE_PATH if needed
        SCRIPT_PATH=""
        NODE_PATH_PREFIX=""
        if [ -f ".gui-test-review-action/scripts/generate-webpage.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/generate-webpage.js"
          NODE_PATH_PREFIX="NODE_PATH=.gui-test-review-action/node_modules:$NODE_PATH"
        elif [ -f "${{ github.action_path }}/scripts/generate-webpage.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/generate-webpage.js"
        elif [ -f "scripts/generate-webpage.js" ]; then
          SCRIPT_PATH="scripts/generate-webpage.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          eval "$NODE_PATH_PREFIX node \"$SCRIPT_PATH\""
        else
          echo "âš ï¸ Dashboard script not found, skipping dashboard generation"
        fi
        echo "âœ… Visual dashboard generation completed"
      continue-on-error: true
    
    - name: Create comprehensive test summary with visual comparison
      id: test-summary
      shell: bash
      run: |
        echo "ğŸ“Š Creating comprehensive test summary with visual analysis..."
        
        # Initialize variables for analysis
        PR_TOTAL=0; PR_PASSED=0; PR_FAILED=0; PR_SKIPPED=0; PR_RATE=0
        MAIN_TOTAL=0; MAIN_PASSED=0; MAIN_FAILED=0; MAIN_SKIPPED=0; MAIN_RATE=0
        REGRESSION="false"
        
        # Analyze PR branch results
        if [ -f "artifacts/playwright-summary-pr.json" ]; then
          if command -v jq &> /dev/null; then
            PR_TOTAL=$(jq -r '.total // 0' artifacts/playwright-summary-pr.json)
            PR_PASSED=$(jq -r '.passed // 0' artifacts/playwright-summary-pr.json)
            PR_FAILED=$(jq -r '.failed // 0' artifacts/playwright-summary-pr.json)
            PR_SKIPPED=$(jq -r '.skipped // 0' artifacts/playwright-summary-pr.json)
            PR_RATE=$(jq -r '.pass_rate // 0' artifacts/playwright-summary-pr.json)
            
            echo "PR GUI Tests: $PR_TOTAL total, $PR_PASSED passed, $PR_FAILED failed ($PR_RATE% pass rate)"
          fi
        fi
        
        # Analyze main branch results for comparison
        if [ -f "artifacts/playwright-summary-main.json" ] && [ "${{ inputs.enable-visual-comparison }}" = "true" ]; then
          if command -v jq &> /dev/null; then
            MAIN_TOTAL=$(jq -r '.total // 0' artifacts/playwright-summary-main.json)
            MAIN_PASSED=$(jq -r '.passed // 0' artifacts/playwright-summary-main.json)
            MAIN_FAILED=$(jq -r '.failed // 0' artifacts/playwright-summary-main.json)
            MAIN_SKIPPED=$(jq -r '.skipped // 0' artifacts/playwright-summary-main.json)
            MAIN_RATE=$(jq -r '.pass_rate // 0' artifacts/playwright-summary-main.json)
            
            echo "Main GUI Tests: $MAIN_TOTAL total, $MAIN_PASSED passed, $MAIN_FAILED failed ($MAIN_RATE% pass rate)"
            
            # Detect visual regression
            if [ "$PR_FAILED" -gt "$MAIN_FAILED" ] || [ $(echo "$PR_RATE < $MAIN_RATE" | bc -l 2>/dev/null || echo "0") -eq 1 ]; then
              REGRESSION="true"
              echo "âš ï¸ GUI test regression detected!"
            fi
          fi
        fi
        
        # Create visual comparison summary
        VISUAL_COMPARISON="{\"pr\":{\"total\":$PR_TOTAL,\"passed\":$PR_PASSED,\"failed\":$PR_FAILED,\"skipped\":$PR_SKIPPED,\"pass_rate\":$PR_RATE},\"main\":{\"total\":$MAIN_TOTAL,\"passed\":$MAIN_PASSED,\"failed\":$MAIN_FAILED,\"skipped\":$MAIN_SKIPPED,\"pass_rate\":$MAIN_RATE},\"regression_detected\":$REGRESSION}"
        
        # Set comprehensive outputs
        echo "results={\"total\":$PR_TOTAL,\"passed\":$PR_PASSED,\"failed\":$PR_FAILED,\"pass_rate\":$PR_RATE}" >> $GITHUB_OUTPUT
        echo "pr-results={\"total\":$PR_TOTAL,\"passed\":$PR_PASSED,\"failed\":$PR_FAILED,\"skipped\":$PR_SKIPPED,\"pass_rate\":$PR_RATE}" >> $GITHUB_OUTPUT
        echo "main-results={\"total\":$MAIN_TOTAL,\"passed\":$MAIN_PASSED,\"failed\":$MAIN_FAILED,\"skipped\":$MAIN_SKIPPED,\"pass_rate\":$MAIN_RATE}" >> $GITHUB_OUTPUT
        echo "visual-comparison=$VISUAL_COMPARISON" >> $GITHUB_OUTPUT
        echo "regression-detected=$REGRESSION" >> $GITHUB_OUTPUT
        echo "total-tests=$PR_TOTAL" >> $GITHUB_OUTPUT
        echo "pass-rate=$PR_RATE" >> $GITHUB_OUTPUT
        
        echo "âœ… Comprehensive visual test analysis completed"
      continue-on-error: true
    
    - name: Extract code quality metrics
      id: lint-summary
      shell: bash
      run: |
        echo "ğŸ“ˆ Extracting code quality metrics..."
        QUALITY_SCORE=100
        
        if [ -f "artifacts/lint-summary.json" ]; then
          if command -v jq &> /dev/null; then
            ESLINT_ERRORS=$(jq -r '.eslint.errors // 0' artifacts/lint-summary.json)
            PRETTIER_ISSUES=$(jq -r '.prettier.filesWithIssues // 0' artifacts/lint-summary.json)
            
            # Calculate quality score (simple algorithm)
            QUALITY_SCORE=$((100 - ESLINT_ERRORS * 5 - PRETTIER_ISSUES * 2))
            if [ $QUALITY_SCORE -lt 0 ]; then QUALITY_SCORE=0; fi
            
            echo "Code Quality Score: $QUALITY_SCORE/100"
          fi
        fi
        
        echo "quality-score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
        echo "âœ… Code quality metrics extracted"
      continue-on-error: true
    
    - name: Upload visual artifacts for code reviewers
      uses: actions/upload-artifact@v4
      with:
        name: gui-test-visual-artifacts
        path: artifacts/
        retention-days: ${{ inputs.artifacts-retention-days }}
      continue-on-error: true
    
    - name: Deploy visual dashboard to GitHub Pages
      id: deploy-report
      if: inputs.enable-github-pages == 'true' && always()
      uses: actions/deploy-pages@v4
      with:
        artifact_name: gui-test-visual-artifacts
        path: artifacts/web-report
      continue-on-error: true
    
    - name: Post comprehensive visual feedback to PR
      if: inputs.enable-pr-comments == 'true' && github.event_name == 'pull_request' && always()
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        ARTIFACTS_DIR: artifacts
        WEB_REPORT_URL: ${{ inputs.web-report-url || steps.deploy-report.outputs.page_url || format('https://{0}.github.io/{1}/', github.repository_owner, github.event.repository.name) }}
      run: |
        echo "ğŸ’¬ Posting comprehensive visual feedback to PR..."
        
        # Determine script location and set NODE_PATH if needed
        SCRIPT_PATH=""
        NODE_PATH_PREFIX=""
        if [ -f ".gui-test-review-action/scripts/summary-comment.js" ]; then
          SCRIPT_PATH=".gui-test-review-action/scripts/summary-comment.js"
          NODE_PATH_PREFIX="NODE_PATH=.gui-test-review-action/node_modules:$NODE_PATH"
        elif [ -f "${{ github.action_path }}/scripts/summary-comment.js" ]; then
          SCRIPT_PATH="${{ github.action_path }}/scripts/summary-comment.js"
        elif [ -f "scripts/summary-comment.js" ]; then
          SCRIPT_PATH="scripts/summary-comment.js"
        fi
        
        if [ -n "$SCRIPT_PATH" ]; then
          eval "$NODE_PATH_PREFIX node \"$SCRIPT_PATH\""
        else
          echo "âš ï¸ Summary comment script not found, skipping PR comment"
        fi
        echo "âœ… Visual feedback posted to PR"
      continue-on-error: true
    
    - name: Validate GUI test results
      if: inputs.fail-on-test-failure == 'true'
      shell: bash
      run: |
        echo "ğŸ” Validating GUI test results..."
        if [ -f "artifacts/playwright-summary-pr.json" ]; then
          if command -v jq &> /dev/null; then
            FAILED=$(jq -r '.failed // 0' artifacts/playwright-summary-pr.json)
            if [ "$FAILED" -gt 0 ]; then
              echo "âŒ GUI tests failed: $FAILED test failures detected"
              echo "ğŸ” Check the visual dashboard for detailed analysis"
              exit 1
            fi
          fi
        fi
        echo "âœ… All GUI tests passed successfully"
    
    - name: Final summary for code reviewers
      if: always()
      shell: bash
      run: |
        echo ""
        echo "ğŸ‰ GUI-Based Testing Code Review Analysis Complete!"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“Š Visual artifacts and comprehensive feedback generated"
        echo "ğŸ¨ Interactive dashboard deployed for code reviewers"
        echo "ğŸ’¬ PR comments updated with visual context"
        echo "ğŸ“‹ Review checklist created for quality assurance"
        echo ""
        echo "ğŸ” Code reviewers can now:"
        echo "  â€¢ View visual test execution flow"
        echo "  â€¢ Compare PR vs main branch GUI test results"
        echo "  â€¢ Access comprehensive code quality feedback"
        echo "  â€¢ Review generated screenshots and artifacts"
        echo ""
        if [ -f "artifacts/test-summary.txt" ]; then
          echo "ğŸ“ˆ Summary:"
          cat artifacts/test-summary.txt
        fi
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"